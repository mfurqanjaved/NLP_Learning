{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Ship classification in synthetic aperture radar (SAR)\n",
    "images is a fundamental and significant step in ocean surveillance. Recently, with the rise of deep learning (DL), modern\n",
    "abstract features from convolutional neural networks (CNNs)\n",
    "have hugely improved SAR ship classification accuracy. However,\n",
    "most existing CNN-based SAR ship classifiers overly rely on\n",
    "abstract features, but uncritically abandon traditional mature\n",
    "hand-crafted features, which may incur some challenges for\n",
    "further improving accuracy. Hence, this article proposes a novel\n",
    "DL network with histogram of oriented gradient (HOG) feature\n",
    "fusion (HOG-ShipCLSNet) for preferable SAR ship classification.\n",
    "In HOG-ShipCLSNet, four mechanisms are proposed to ensure\n",
    "superior classification accuracy, that is, 1) a multiscale classification mechanism (MS-CLS-Mechanism); 2) a global self-attention\n",
    "mechanism (GS-ATT-Mechanism); 3) a fully connected balance\n",
    "mechanism (FC-BAL-Mechanism); and 4) an HOG feature\n",
    "fusion mechanism (HOG-FF-Mechanism). We perform sufficient\n",
    "ablation studies to confirm the effectiveness of these four mechanisms. Finally, our experimental results on two open SAR\n",
    "ship datasets (OpenSARShip and FUSAR-Ship) jointly reveal\n",
    "that HOG-ShipCLSNet dramatically outperforms both modern\n",
    "Manuscript received January 27, 2021; revised March 20, 2021 and April 20,\n",
    "2021; accepted May 10, 2021. Date of publication June 2, 2021; date of\n",
    "current version January 12, 2022. This work was supported in part by\n",
    "the National Natural Science Foundation of China under Grant 61571099,\n",
    "Grant 61501098, and Grant 61671113 and in part by the National Key\n",
    "Research and Development Program of China under Grant 2017YFB0502700.\n",
    "(Corresponding author: Xiaoling Zhang.)\n",
    "Tianwen Zhang, Xiaoling Zhang, Xiao Ke, Xiaowo Xu, Xu Zhan,\n",
    "Chen Wang, Hao Su, Jun Shi, and Shunjun Wei are with the School of\n",
    "Information and Communication Engineering, University of Electronic\n",
    "Science and Technology of China, Chengdu 611731, China (e-mail:\n",
    "twzhang@std.uestc.edu.cn; xlzhang@uestc.edu.cn; xke@std.uestc.edu.cn;\n",
    "xuxiaowo@std.uestc.edu.cn; zhanxu@std.uestc.edu.cn; chenwang@std.\n",
    "uestc.edu.cn; suhao@std.uestc.edu.cn; shijun@uestc.edu.cn; weishunjun@\n",
    "uestc.edu.cn).\n",
    "Chang Liu is with the College of Information Science and Technology, Dalian Maritime University, Dalian 116026, China (e-mail:\n",
    "liuchang@dlmu.edu.cn).\n",
    "Israr Ahmad is with the State Key Laboratory of Information Engineering in\n",
    "Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan 430074,\n",
    "China (e-mail: israrahmad@whu.edu.cn).\n",
    "Yue Zhou is with the School of Electronic Information and Electrical\n",
    "Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail:\n",
    "sjtu_zy@sjtu.edu.cn).\n",
    "Dece Pan is with the Aerospace Information Research Institute,\n",
    "Chinese Academy of Sciences, Beijing 100194, China (e-mail:\n",
    "pandece19@mails.ucas.ac.cn).\n",
    "Jianwei Li is with the 3rd Graduate Student Team, Naval Aviation\n",
    "University, Yantai 264000, China (e-mail: lgm_jw@163.com).\n",
    "Digital Object Identifier 10.1109/TGRS.2021.3082759\n",
    "CNN-based methods and traditional hand-crafted feature\n",
    "methods.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(paragraph)\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentence)):\n",
    "    words = nltk.word_tokenize(sentence[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentence[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship classification synthetic aperture radar ( SAR ) image fundamental significant step ocean surveillance .',\n",
       " 'Recently , rise deep learning ( DL ) , modern abstract feature convolutional neural network ( CNNs ) hugely improved SAR ship classification accuracy .',\n",
       " 'However , existing CNN-based SAR ship classifier overly rely abstract feature , uncritically abandon traditional mature hand-crafted feature , may incur challenge improving accuracy .',\n",
       " 'Hence , article proposes novel DL network histogram oriented gradient ( HOG ) feature fusion ( HOG-ShipCLSNet ) preferable SAR ship classification .',\n",
       " 'In HOG-ShipCLSNet , four mechanism proposed ensure superior classification accuracy , , 1 ) multiscale classification mechanism ( MS-CLS-Mechanism ) ; 2 ) global self-attention mechanism ( GS-ATT-Mechanism ) ; 3 ) fully connected balance mechanism ( FC-BAL-Mechanism ) ; 4 ) HOG feature fusion mechanism ( HOG-FF-Mechanism ) .',\n",
       " 'We perform sufficient ablation study confirm effectiveness four mechanism .',\n",
       " 'Finally , experimental result two open SAR ship datasets ( OpenSARShip FUSAR-Ship ) jointly reveal HOG-ShipCLSNet dramatically outperforms modern Manuscript received January 27 , 2021 ; revised March 20 , 2021 April 20 , 2021 ; accepted May 10 , 2021 .',\n",
       " 'Date publication June 2 , 2021 ; date current version January 12 , 2022 .',\n",
       " 'This work supported part National Natural Science Foundation China Grant 61571099 , Grant 61501098 , Grant 61671113 part National Key Research Development Program China Grant 2017YFB0502700 .',\n",
       " '( Corresponding author : Xiaoling Zhang . )',\n",
       " 'Tianwen Zhang , Xiaoling Zhang , Xiao Ke , Xiaowo Xu , Xu Zhan , Chen Wang , Hao Su , Jun Shi , Shunjun Wei School Information Communication Engineering , University Electronic Science Technology China , Chengdu 611731 , China ( e-mail : twzhang @ std.uestc.edu.cn ; xlzhang @ uestc.edu.cn ; xke @ std.uestc.edu.cn ; xuxiaowo @ std.uestc.edu.cn ; zhanxu @ std.uestc.edu.cn ; chenwang @ std .',\n",
       " 'uestc.edu.cn ; suhao @ std.uestc.edu.cn ; shijun @ uestc.edu.cn ; weishunjun @ uestc.edu.cn ) .',\n",
       " 'Chang Liu College Information Science Technology , Dalian Maritime University , Dalian 116026 , China ( e-mail : liuchang @ dlmu.edu.cn ) .',\n",
       " 'Israr Ahmad State Key Laboratory Information Engineering Surveying , Mapping , Remote Sensing , Wuhan University , Wuhan 430074 , China ( e-mail : israrahmad @ whu.edu.cn ) .',\n",
       " 'Yue Zhou School Electronic Information Electrical Engineering , Shanghai Jiao Tong University , Shanghai 200240 , China ( e-mail : sjtu_zy @ sjtu.edu.cn ) .',\n",
       " 'Dece Pan Aerospace Information Research Institute , Chinese Academy Sciences , Beijing 100194 , China ( e-mail : pandece19 @ mails.ucas.ac.cn ) .',\n",
       " 'Jianwei Li 3rd Graduate Student Team , Naval Aviation University , Yantai 264000 , China ( e-mail : lgm_jw @ 163.com ) .',\n",
       " 'Digital Object Identifier 10.1109/TGRS.2021.3082759 CNN-based method traditional hand-crafted feature method .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ps = PorterStemmer()\n",
    "wordnet = WordNetLemmatizer()\n",
    "sentence = nltk.sent_tokenize(paragraph)\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentence[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recently, with the rise of deep learning (DL), modern\\nabstract features from convolutional neural networks (CNNs)\\nhave hugely improved SAR ship classification accuracy.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recently rise deep learning dl modern abstract feature convolutional neural network cnns hugely improved sar ship classification accuracy'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "h = tf_idf.fit_transform(corpus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.22974776, 0.        , 0.        ,\n",
       "       0.        , 0.20652277, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18850806, 0.        ,\n",
       "       0.        , 0.        , 0.26248155, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.26248155, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.26248155, 0.        , 0.        , 0.22974776,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.17378897, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.26248155, 0.        , 0.        , 0.26248155, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.26248155, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.22974776,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.22974776,\n",
       "       0.26248155, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.26248155, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.26248155, 0.17378897,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.17378897, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
